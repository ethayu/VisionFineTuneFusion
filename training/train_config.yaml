dino_model_name: "facebook/dinov2-large"
clip_model_name: "openai/clip-vit-base-patch32"
data_dir: "data/processed"
save_path: "results/checkpoints/autoencoder.pth"
# device: "cuda"  # or "cpu"
device: "cpu"

batch_size: 8
epochs: 10
learning_rate: 0.0001
scheduler_step: 5
scheduler_gamma: 0.5

latent_dim: 512 # needs to be same as CLIP latent dim
cls_dim: 1024
lambda_reconstruction: 1.0
lambda_clip_image: 0.5
lambda_clip_text: 0.5

patch_dim: 1024
# changed patch dim from 768
latent_dim_patch: 512
lambda_patch_reconstruction: 0.5
lambda_patch_clip: 1.0
lambda_cls_reconstruction: 1.0
lambda_cls_clip: 0.5
num_patches: 256

save_path_cls: cls_model
save_path_patch: patch_model